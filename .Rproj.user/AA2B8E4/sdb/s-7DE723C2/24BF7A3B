{
    "contents" : "## Getting and Cleaning Data - course project\n## A full description is available at the site where the data was obtained:\n## http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\n## Here are the data for the project:\n## https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip\n## You should create one R script called run_analysis.R that does the following.\n## 1. Merges the training and the test sets to create one data set.\n## 2. Extracts only the measurements on the mean and standard deviation for each measurement.\n## 3. Uses descriptive activity names to name the activities in the data set.\n## 4. Appropriately labels the data set with descriptive activity names.\n## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.\n\n\n## 1. Merge the training and test sets\n## Check if UCI HAR Dataset exists \n## Otherwise create new folder called \"Getting Data Project\", download zipped dataset and unzip\n## Note files will be automatically extracted into another new folder called UCI HAR Dataset\n## List file names to get an idea of what is in the file\n\npath <- getwd()\nif (!file.exists(\"UCI HAR Dataset\")) \n    {url <- \"http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip\"\n    zipfile <- \"Dataset.zip\"\n    download.file(url, zipfile)\n    unzip(zipfile, overwrite=TRUE)}\n    input <- file.path(\"UCI HAR Dataset\")\n\nlist.files(input, all.files=FALSE, recursive=TRUE)\n\n## No need to use Inertial Signals folders as explained in course discussion forum\n## Readme says train/X_train.txt=training set, train/y_train.txt=training labels and train/subject_train.txt=subjects\n## Read training files and give names to columns in label and subject file\n## Merge files  (each has 7,352 obs of 1 var so cbind)\n\ntrainset <- read.table(file.path(input,\"train\",\"X_train.txt\"))\ntrainlabel <- read.table(file.path(input,\"train\",\"y_train.txt\"))\ncolnames(trainlabel) <- \"Label\"\ntrainsubject <- read.table(file.path(input,\"train\",\"subject_train.txt\"))\ncolnames(trainsubject) <- \"Subject\"\nmergetrain <- cbind(trainsubject, trainlabel, trainset)\n\n## Readme says test/X_test.txt=test set, test/y_test.txt=test labels and test/subject_test.txt=subjects\n## Read test files and give names to columns in label and subject file\n## Merge files  (each has 2,947 obs of 1 var so cbind)\n\ntestset <- read.table(file.path(input,\"test\",\"X_test.txt\"))\ntestlabel <- read.table(file.path(input,\"test\",\"y_test.txt\"))\ncolnames(testlabel) <- \"Label\"\ntestsubject <- read.table(file.path(input,\"test\",\"subject_test.txt\"))\ncolnames(testsubject) <- \"Subject\"\nmergetest <- cbind(testsubject, testlabel, testset)\n\n## Merge test and train sets - both have 561 variables so use rbind\n\nmergeset <- rbind(mergetrain, mergetest)\n\n\n## 2. Extract only the measurements on the mean and standard deviation \n## Read the file features.txt for all the measurement names and append to merged dataset\n\nfeatures <- read.table(file.path(input, \"features.txt\"))\nfeaturename <- as.character(features[,2])\nheaders <- c(\"Subject\", \"Label\", featurename)\ncolnames(mergeset) <- headers\n\n## Identify and subset columns measuring mean or standard deviation\n## Only extracts those with mean() or std() at end as those are true measures of mean or std in this context\n\nmergeset1 <- mergeset[, 1:2]\nmergeset2 <- mergeset[(grepl((\"mean\\\\(\\\\)|std\\\\(\\\\)\"), headers))]\nmergesubset <- cbind(mergeset1, mergeset2)\n\n\n## 3. Uses descriptive activity names to name the activities in the data set\n## Read activity names in activity_labels.txt file\n\nactivity <- read.table(file.path(input, \"activity_labels.txt\"))\ncolnames(activity) = c(\"Label\", \"Activity\")\n\n## Merge \"activity\" with dataset \nmergesubset <- merge(mergesubset, activity, by=\"Label\", all.x=TRUE)\n\n## Order by subject, remove Label column and rearrange data set so Activity is second column\nmergesubset <- mergesubset[, c(2,69,3:68)]\nmergefinal <- mergesubset[order(mergesubset$Subject), ]\n\n\n## 4. Appropriately label the data set with descriptive activity names\n## Replace abbreviations with fuller descriptions as laid out in features_info.txt\n## Also remove special characters\nnames(mergefinal) <- tolower(names(mergefinal))\nnames(mergefinal) <- sub(\"^t\", \"time\", names(mergefinal))\nnames(mergefinal) <- sub(\"^f\", \"frequency\", names(mergefinal))\nnames(mergefinal) <- gsub(\"acc\", \"acceleration\", names(mergefinal))\nnames(mergefinal) <- gsub(\"std\", \"standarddeviation\", names(mergefinal))\nnames(mergefinal) <- gsub(\"mag\", \"magnitude\", names(mergefinal))\nnames(mergefinal) <- gsub(\"gyro\", \"gyroscope\", names(mergefinal))\nnames(mergefinal) <- gsub(\"-\",\"\", names(mergefinal))\nnames(mergefinal) <- gsub(\"\\\\(|\\\\)\", \"\", names(mergefinal))\n\n\n## 5. Create a second, independent tidy data set with the average of \n## each variable for each activity and each subject\n\n## Activate dplyr library, group table by subject and activity, and find the mean of each\n## remaining column by subject and activity\nlibrary(dplyr)\nmergesum <- mergefinal %>%\n  group_by(subject, activity) %>%\n  summarise_each(funs(mean))\n\n## Write final data set to txt file in working directory\nwrite.table(mergesum, \"tidyanalysis.txt\", row.names=FALSE)",
    "created" : 1413964861630.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1831276278",
    "id" : "24BF7A3B",
    "lastKnownWriteTime" : 1414055027,
    "path" : "C:/Users/Fiona/Dropbox/DataScience/Getting and Cleaning Data/GettingDataProject/run_analysis.R",
    "project_path" : "run_analysis.R",
    "properties" : {
        "notebook_format" : "html_document",
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}